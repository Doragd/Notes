# 《概率论和数理统计》阅读笔记

> 摘录一些我不熟悉和可能有用的观点，公式和知识

## 事件的概率


### 概率是什么

!!! tip "例子"
    丢一枚骰子，丢到3的概率为1/6，丢到小于等于5的概率是5/6。

* 随机试验：丢一枚骰子。注意：人只是处在被动地位去“观察”试验结果，人就是观测者。
* 样本空间：一次随机试验所有可能结果的集合，比如丢一个骰子，样本空间为$\{{1,2,3,4,5,6\}}$。
* 事件：样本空间的一个子集，即全部可能结果中确定的一部分，比如定义事件$E_{1}=\{{掷出偶数点\}}=\{{2,4,6\}}$。
* 概率：某种情况(事件)出现的可能性大小，介于0，1之间。

* 概率的统计定义:
1. 从实用的角度看，概率的统计定义就是通过试验去估计事件概率的方法。一事件出现的可能性大小，应该由多次重复试验中其出现的频繁程度去刻画。
2. 上述定义不足之处在于频率只是概率的估计而非概率本身。形式上可以说事件$E$的概率$p$就是当试验次数无限增大时频率的极限。但这样做的话，必须说明$p$是否存在，抑或$p$的存在只是一个假定？
3. 实际上，这个统计定义并没有提供清晰定义出任何一个事件的概率的方法，它的用处在于：提供了一个种估计概率的方法——比如用抽样的样本去估计整个总体的xx比例。同时，提供了一种检验理论正确与否的准则——比如我们通过一定理论和假定算出某事件概率$p$，这理论和假定是否与实际相符的检验方法为诉诸大量重复实验观察事件发生的频率是否与$p$接近。

### 条件概率和事件独立性

* 条件概率：设有两事件$A,B$，且$P(B) \neq 0$，则“给定B发生的条件下A的条件概率”，记为$P(A|B)$，定义为
$$
P(A|B)=P(AB)/P(B), P(AB)=P(B)P(A|B)
$$

* 事件独立性(概率乘法定理)：B的发生与否对A的发生毫无影响，即若两事件满足$P(AB)=P(A)P(B)$，则称A,B独立。多个独立事件的积的概率等于各自概率之积。实际问题中，一般是从事件的实际角度分析判断事件之间是否有关联。比如一个人的收入和他姓氏的笔画是相互独立的。

### 全概率公式和贝叶斯公式

* 完备事件群：设$B_1,B_2,...$为有限或无限个事件，它们两两互斥且每次试验中至少发生一个，把这样的一组事件叫做完备事件群。即：$B_iB_j=\empty, B_1+B_2+...=\Omega$。任意一个事件与其对立事件组成一个完备事件群。
* 全概率公式：考虑任一事件A，其作用在于，在较复杂的情况下直接算P(A)不易，但A总随某个$B_i$伴出，适当构造这一组完备事件群可以简化计算。另一种理解：把$B_i$看作导致A发生的一种可能途径。对不同途径，A发生的概率即条件概率$P(A|B_i)$各不同，而采取哪个路径则是随机的。在这种机制下，A的综合概率P(A)应该是各个P(A|B_i)以$B_i$为权的加权平均值。比如若干工厂生成同一产品，废品率各个不同，将各个厂的产品汇总，总废品率为各厂废品率的加权平均，权与各厂产量成比例。
$$
P(A)=P(AB_1)+P(AB_2)+...=P(B_1)P(A|B_1)+P(B_2)P(A|B_2)+...
$$
* 贝叶斯公式：我们把事件A看作结果，事件$B_1,B_2,...$看作导致这结果可能的原因，则全概率公式为由原因推结果，而贝叶斯公式则是由结果推原因：现在有一个结果A发生了，求哪一个原因是最有可能的。

$$
P(B_i|A)=P(AB_i)/P(A)=P(B_i)P(A|B_i)/\sum_{j}{P(B_j)P(A|B_j)}
$$
  
!!! tip "例子"
    某地发生了一个刑事案件，按照平日掌握的资料，嫌疑人有张三，李四等。在人们不知道案情细节$A$的情况下，依据他们过去在局子的记录对他们作案可能性有个估计，相当于$P(B_1),P(B_2),...$。但是现在知道案情后，这个估计就有了变化，比如张三之前不可能，后来成了重点嫌疑人。

即对于$P(B_1),P(B_2)$是人们在不知道A是否发生的情况下，对诸事件发生可能性的认识，现在有了新的信息，即A发生，人们对$B_1,B_2,...$诸事件发生可能性大小有了新的估计。

* 贝叶斯公式在统计学中作用：依靠收集的数据，即事件A，去寻找所感兴趣的问题的答案，这是一个由结果找原因的过程。根据这个公式思想，而后又发展了整套统计推断方法，叫贝叶斯统计。

## 随机变量及概率分布

### 随机变量

* 随机变量：其值随机会而定的变量，是试验结果的函数。在试验前，我们不知道它取何值，试验后，取值则确定了。比如在买彩票试验中，彩票中奖金额$X$为一个随机变量，其值要等开奖后才确定下来。
> 一大堆例子：从某厂大批产品中随机抽出100个，其中含废品数X，用天平称某物体重量的误差X，一个月内交通路口事故数X。打靶实验，命中位置由(X,Y)坐标刻画，(X,Y)就是二维随机变量，推广开来，多维随机向量为$(X_1,X_2,...)$

离散型随机变量：取值有限可列。

* 概率函数：X为离散型随机变量，其全部取值为$\{{a_1,a_2,...\}}$，则$p_i=P(X=a_i),i=1,2,...$为X的概率函数。对离散型而言，用概率函数来描述概率分布是最方便的。


* 概率分布：实际上，这个函数给出了概率在其可能取值集合上的分布情况(横坐标是取值，纵坐标是概率)，故又称上式为X的概率分布。也就是说概率分布就是概率在其可能取值集合上的分布情况，其数学形式可以是概率函数，概率密度函数，分布函数。随机变量服从某某分布，意思是随机变量在其可能取值集合上的概率分布情况服从某某分布的分布规律(概率函数/概率密度函数/分布函数)。


* 分布函数: 随机变量也可以用分布函数去描述其概率分布。设X为一随机变量，则函数$P(X\leq x)=F(x),-\infty < x < \infty$ 称为X的分布函数。
	* 分布函数是单调非降的
	* 当$x\rightarrow \infty, F(x)\rightarrow0;x\rightarrow -\infty,F(x)\rightarrow1$

连续型随机变量：取值充满一个区间，无法一一列出。
* 概率密度函数：刻画连续型的概率分布最好用概率密度函数。设连续型随机变量X有概率分布函数$F(x)$, 则$F(x)$的导数$f(x)=F'(x)$称为X的概率密度函数
	* 显然：$f(x)\geq 0$
	* 全部概率为1：$\int_{-\infty}^{\infty} f(x) \mathrm{d} x=1$
	* 牛顿莱布尼兹公式：对任意常数a,b,有$P(a \leqslant X \leqslant b)=F(b)-F(a)=\int_{a}^{b}(x) \mathrm{d} x$
* 概率密度函数的理解：取一个点$x$, 事件$\{{x\leq X\leq x+h\}}$的概率为$F(x+h)-F(x)$。那么$(F(x+h)-F(x))/h$表示在$x$附近长为$h$的区间中，单位长度占有的概率! $h\rightarrow 0$即$F'(x)=f(x)$表示在概率在$x$点处的密集程度。

多维随机向量: $X=(X_1,X_2,...)$ 每个分量都是一维随机变量

离散型多维随机向量：每个分量都是一维离散型随机变量

!!! tip "离散型多维随机向量的概率函数的例子"
	$P\left(X_{1}=2, X_{2}=1\right)=1 / 3$

	$P\left(X_{1}=2, X_{2}=2.5\right)=1 / 4$

	$P\left(X_{1}=5, X_{2}=3\right)=5 / 12$
	
	实际上取值情况有6种，不过其概率分布告诉我们，实际只有3组可能的取值。

连续随机向量的分布：设$X=(X_1,X_2,...)$是一个$n$维随机向量，取值可视为$n$维欧氏空间$\mathbb{R}^n$中的一个点，如果$X$的全部取值可以充满$\mathbb{R}^n$中某一个区域，则它是连续型的。

概率密度函数： 引入记号$X\in A$表示“X落进A内，或者X属于A”，A是$\mathbb{R}^n$中集合，$\{{X\in A\}}$是一个事件。若$f(x_1,x_2,...,x_n)$为定义在 $\mathbb{R}^n$ 的非负函数，使得对$\mathbb{R}^n$中的任何集合A，有
$$
P(X \in A)=\int_{A} \cdots \int f\left(x_{1}, \cdots, x_{n}\right) d x_{1} \cdots d x_{n}
$$

### 常见分布和例子

#### 二项分布：

* 定义:

事件A在一次试验中发生的概率为$p$，进行$n$次独立重复实验，$X$为事件A在$n$次试验中发生的次数，则X取值为$\{{0,1,2,...,n\}}$。考虑事件$\{{X=i\}}$, 其概率为
$$
p_{i}=b(i ; n, p)=\left(\begin{array}{c}
{n} \\
{i}
\end{array}\right) p^{i}(1-p)^{n-i}, i=0,1, \cdots, n
$$
$X$所遵循的分布称为二项分布，记为$X \sim B(n, p)$

* 关键点:该分布需要两个重要条件，一是各次试验的条件稳定，保证了事件A的概率$p$在各次试验中保持不变，二是各次试验的独立性。

* 例子：现实生活中许多现象不同程度地符合这些条件，不一定分毫不差，可以近似大体上服从。

!!! tip "例子"
	一大批产品$N$个，废品率为$p$，从中逐一抽取产品检验是否为废品，共抽$n$个。有放回抽样，保证每个产品抽出机会相同，则$n$个产品中所含废品数$X$相当理想服从二项分布。如果不放回，则下次抽取时，废品率就会发生变化，不再服从。如果$N$远大于$n$, 则即使不放回对废品率影响也极小，则近似二项分布。


#### 正态分布
* 定义：如果一个随机变量具有概率密度函数 
$f(x)=(\sqrt{2 \pi} \sigma)^{-1} \mathrm{e}^{-(x-\mu)^{2} / 2 \sigma^{2}},-\infty<x<\infty$ 则 该随机变量服从正态分布，记为$X \sim N\left(\mu, \sigma^{2}\right)$，$\mu$可以取任何值，$\sigma^2$大于0，两者均为概率分布的参数
* 















